# ClimateData
Crawling and preserving climate data

For dockets:
TODO:
 -
 - [ ] Get links for each document and attachment
 - [ ] Download and save each document
   - [ ] Check each possible doc type and ensure its saved properly
 - [ ] Automate finding how many documents in each docket
 - [ ] Find/Create database to store everything, automate saving crawls directly to database (Archivers app?)
   - [ ] If using WUSTL box -> use the box api to put docs there directly
 - [ ] Hash documents for data integrity

In Progress:
 -

Review/Testing:
 -

Finished:
 -
 - [x] For each docket, start a crawl for Primary, Supporting, and Comments
 - [x] Get all links to document pages


